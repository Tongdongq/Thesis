\documentclass[../thesis.tex]{subfiles}


\begin{document}

\chapter{Conclusion}
\ifdefined\main
\else
\input{../notmain.tex}
\fi

% two sequences used to make a picture of the Diff_tutorial tool for the defense presentation:
% TCACTTTCGTACGCTACAGCGACAATGATAGTTCCCCAAAACGATAAGAAAAAGTTTCCCTCCGTCTTGCTAGCCCCTTCAACCGAGAGGGCTTTTTCAATTCGCCATTTCTCCTGACAAATCATGCGGATATAAAATTT
%TCGCTACAAGCTGATTAAATGAACTTCACTTCGTAGCGCTACAGCGAAAATGAAGTATCCCGCAGAACGATAACGAAATAAGTTACCTCCCTTCTCTTTGCTAAAGCCCTTCTCAACCGAGAGGGCTTTTTTTCAAATTC

% fix references, especially e.a.
% 

\section{Research questions}
To fulfill the main goal of this thesis, several research questions must be answered:

\begin{itemize}
\item Is it possible to accelerate Daligner and Darwin using a GPU?
\end{itemize}
GPU implementations for both Daligner and Darwin were made.
Many different implementations for Daligner showed improvement, but the fastest implementation is still the CPU version.
Considering the nature of this algorithm, this is not very surprising.
Fine-grained parallelism is not implemented.
It increases the complexity of the implementation, since the median width of the wave is 26, as a result, a warp is not fully utilized half of the time.
Additionally, the overhead of launching a kernel for each wave would become very large.
A substantial speedup can be gained when not calculating Pebbles, this is an actual use case, since FALCON does not use those Pebbles.

Darwin showed better results on GPU.
A naive GPU implementation showed 12x speedup on ce-cuda, with the addition of GASAL, which increased the speedup to 109x.
If scores are not needed, the speedup increases to 148x.
Since Darwin is designed to be hardware-friendly, and has already been successfully implemented on an FPGA, this result is not surprising.

To summarize: for Daligner: no, for Darwin: yes.


\begin{itemize}
\item Can we tweak Daligner and Darwin to trade performance, sensitivity and specificity?
\end{itemize}
Both Daligner and Darwin allow the user to tweak the algorithm using parameters.
Darwin shows a very clear relation between the number of seeds and the runtime.
The number of seeds also impacts the sensitivity, and to a lesser extend, the specificity.
For Daligner, both k and h can be used to affect the runtime and sensitivity, they seem to have a similar impact.

The CPU scaling for Daligner is much better than for Darwin.
This makes sense, since Darwin uses the GPU to perform GACT.
Darwin benefits from more CPU threads because preparing tiles can be done in parallel, as well as reading the seedposition table to find seeds.

A clear tradeoff between sensitivity and specificity can be observed from the experiments.
This shows that both algorithms can be configured to suit the input requirements of later stages in the assembly pipeline.


\todo{be more precise with numbers}
\todo{fix references}

\begin{itemize}
\item How do Daligner and Darwin relate to each other with respect to runtime, sensitivity and specificity?
\end{itemize}
Daligner can produce more sensitive alignments in a shorter time on both tested systems, while using less memory.
For high sensitivity (99+\%), Daligner is almost 3x faster on ce-cuda, and 5x on TACC.
\todo{include lower sensitivity (95\%)}

The main advantage of Darwin is that is calculates an actual Smith-Waterman score.
This means Darwin can be configured to prefer substitutions or gaps, and customize it to suit a particular sequencing technology.
GACT is also empirically shown to produce the same output as Smith-Waterman and is capable of producing MAF files, whereas the extend phase of Daligner only reports the positions, and the number of differences.

Daligner is probably more useful in any kind of DNA assembler, unless alignments need to have specific traits.
Daligner also scales better on CPU threads.
An environment in which Darwin could be better is when there is lots of GPU computing power, and little CPU power.
However, many systems nowadays have multiple CPU cores, so Daligner remains the better choice in general.
\todo{depending on the application}
\section{Future work}

%TODO future work
% - Yatish told me about transitive overlaps:
% - - if A and B overlap, and B and C too, then A and C probably also overlap

% stuff here depends on the profile results to identify bottlenecks



A way to interpret the produced overlaps more efficiently is to use transitive overlaps.
If reads A and B overlap, and B and C too, then A and C could also overlap.
However, this should only result in marginal improvements of the sensitivity, since the overlap between A and C should already be found.
The authors of Darwin got 0.79\%-point extra sensitivity using this method \cite{Darwin1}.

The CPU version could be optimized as well.
The current multi-threaded version has no load balancing.
All CPU threads get a roughly equal amount of reads that must be tested by D-SOFT.
The number of seeds that emerge can vary (observed values are 17000 and 30655), this is partially caused by the different read lengths.
Another reason for the imbalance is that the extension phase for each seed can have a different duration.
One way to solve this is to create a large list with all the seeds, possibly partitioned so that the threads can write to this list in parallel.
When starting the GACT phase, each thread gets a batch of reads to extend.
When a thread is done with its batch, or has less seeds than GPU threads, it gets another batch from the large list.

Since GASAL is designed to work with affine gap penalties, it uses four arrays to keep track of the score.
If a linear gap penalty is used, it can be reduced to two.
The calculation of the maximum score can also be simplified.
Since this the main part of the algorithm, this could reduce the runtime significantly.

GASAL uses four bits to represent a base, which allows one integer to hold eight bases, which explains the 8x8 access pattern.
The matrices that hold the scores are reduced to 9-element arrays, which are put in the registers.
If the GASAL tiles are made smaller, for example 4x4, these arrays should only be 5 elements wide.
This reduces the amount of registers per thread, and could allow for more active threads, which could reduce the runtime.
A drawback is the increased number of accesses to the global array, it has to be used every 4 columns, instead of every 8.
This also opens up another possibility, if two bits are used per base, one integer can hold 16 bases.
This means GASAL tiles can be 16x16, halving the required amount of accesses to the global array.
A drawback of this method is that the number of registers is likely to be very high, but this might be compensated by using a linear gap penalty.


\end{document}









