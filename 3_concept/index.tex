\documentclass[../main/thesis.tex]{subfiles}

%\RequirePackage{amsmath}

\begin{document}

\chapter{Concept}
\ifdefined\main
\acresetall
MAIN IS TRUE
\newcommand{\code}{../3_concept/code/}
\else
MAIN IS NOT TRUE
\input{../notmain.tex}
\fi

\section{Pacbio reads}
Daligner finds alignments between long, noisy reads.
Pacific Biosciences has commercially launched its first sequencer in 2011.
It is able to output reads with an average of 1000 bases, which is significantly longer than \ac{NGS} reads \cite{PBlaunch1}.
In 2014, a new polymerase-chemistry combination was released, called P6-C4.
This version can output average read lengths of 10000-15000 bases, and its longest reads can exceed 40000 bases \cite{Longreads}.
While the drawback is that these reads have an error rate of 12-15\%, this can be compensated by the distribution of these errors \cite{Daligner}.
First, the set of reads is a nearly Poisson sampling of the sampled genome.
This implies that there exists a coverage c for every target coverage k, such that every region of the genome is covered k times \cite{Poisson}.
Secondly, the work of Churchill and Waterman \cite{quality} implies that the accuracy of the consensus sequence of k sequences is O($\epsilon^k$), which goes to 0 as k increases.
This means that if the reads are long enough to handle repetitive regions, in principle a near perfect de novo assembly of the genome is possible, given enough coverage.

Important points for de novo DNA sequencing are: what level of coverage is needed for high quality assembly?
And how to build an assembler that is able to deal with high error rates and long reads?
Most previous assemblers work with \ac{NGS} reads, which are much shorter and have much lower error rates.
Some algorithms used in these assemblers, such as \ac{DBG} \cite{DeBruijn} would grow too large for high error rates and long reads.
Since Daligner was build, new methods of using \ac{DBG} with long reads have been developed, but they rely on a short read based \ac{DBG} to correct errors in long reads \cite{DBG1}\cite{DBG2}.

\section{Daligner}

The first step in an \ac{OLC} assembler is usually finding overlaps between reads \cite{OLC}.
BLASR \cite{BLASR} was the only long read aligner at the time, and inpsired Daligner.
It uses the same filtering concept, but with a cache-coherent threaded radix sort to find seeds, instead of a BWT index \cite{BWT}.
%TODO is seed-extend already introduced?
The most time-consuming step is extending the seed hit to find an alignment.
To do this, Daligner uses a novel method which adaptively computes furthest reaching waves of the older O(nd) algorithm \cite{O_ND}, combined with heuristic trimming and a datastructure that describes a sparse path from the seed hit to the furthest reaching point.

%TODO daligner paper includes a small section on results
%TODO next part is copied straight from daligner paper
Daligner performs all-to-all comparison on two input databases $\mathcal{A}$, with $M$ long reads $A_1, A_2,...A_M$ and $\mathcal{B}$, with $N$ long reads $B_1, B_2,...B_N$ over alphabet $\Sigma = 4$
It reports alignments $P = (a,i,g)x(b,j,h)$ such that $len(P) = ((g-i)+(h-j))/2 \ge \tau$ and the optimal alignment between $A_a[i+1,g]$ and $B_b[j+1,h]$ has no more than 2$\epsilon \cdot len(P)$ differences, where a difference can be either an insertion, a deletion or a substitution.
Both $\tau$ and $\epsilon$ are user settable parameters, where $\tau$ is the minimum alignment length and $\epsilon$ the average error rate.
The correlation, or percent identity of the alignment is defined as $1-2\epsilon$.

An edit graph for read $A=a_1a_2...a_m$ and $B=b_1b_2...b_n$ is a graph with $(m+1)(n+1)$ vertices $(i,j) \in [0,M]\times[0,N]$.
It also has three types of edges:
\begin{itemize}
\item deletion edges $(i-1,j) \rightarrow (i,j)$ with label
{\small$\begin{bmatrix}
a_i \\ -
\end{bmatrix}$} if $i > 0$.
\item insertion edges $(i,j-1) \rightarrow (i,j)$ with label 
{\small$\begin{bmatrix}
- \\ b_j
\end{bmatrix}$} if $j > 0$.
\item diagonal edges $(i-1,j-1) \rightarrow (i,j)$ with label
{\small$\begin{bmatrix}
a_i \\ b_j
\end{bmatrix}$} if $i,j > 0$.
\end{itemize}

%TODO insert picture of edit graph

An alignment between $A[i+1,g]$ and $B[j+1,h]$ is described as a sequence of labels from vertex $(i,j)$ to $(g,h)$.
A diagonal edge can be either be a match edge, when $a_i = b_j$, or a substitution edge.
If a match edge has weight 0, and the other edges have weight 1, the weight of the total path is the number of differences in the alignment it represents.
To find suitable alignments, we have to find a read subset pairs P such that $len(P)\ge \tau$ and the weight of the lowest scoring path between $(i,j)$ and $(g,h)$ in the edit graph of $A_a$ and $B_b$ is not more than $2\epsilon\cdot len(P)$.

%TODO include something about SW and if Daligner is actually SW with certain penalty values?
%A naive but exact way to calculate the lowest scoring path is described in the paper from Smith and Waterman \cite{SW}.

The O(ND) algorithm tries to find progressive waves of furthest reaching (f.r.) points until the endpoint is reached.
The goal is to find longest possible paths starting at a starting point $\rho = (i,j)$ with 0 differences, then 1 difference, then 2 and so on.
After d differences, the possible paths can end in diagonals $\kappa \pm d$, where $\kappa = i-j$ is the diagonal of the starting point.
The furthest reaching point on diagonal $k$ that can be reached from $\rho$ with $d$ differences is called $F_\rho(d,k)$.
A collection of these points for a particular value of $d$ is called the $d$-wave emanating from $\rho$, and defined as $W_\rho(d) = \{F_\rho(d,\kappa-d),...,F_\rho(d,\kappa+d)\}$.
$F_\rho(d,k)$ will be refered to as $F(d,k)$, where $\rho$ is implicitely understood from the context.

In the O(ND) paper it is proven that:
\begin{equation}
F(d,k)=Slide(k, max\{F(d-1,k-1)+(1,0), F(d-1,k)+(1,1), F(d-1,k+1)+(0,1)\}
\end{equation}

where $Slide(k,(i,j)) = (i,j) + max\{\Delta:a_{i+1}a_{i+2}...a_{i+\Delta} = b_{j+1}b_{j+2}...b_{j+\Delta}\}$.

A slide is a path of sequential match edges.
The f.r. $d$-point on diagonal $k$ is calculated by finding the furthest of
\begin{itemize}
\item the f.r. ($d$-1)-point on $k-1$ followed by an insertion
\item the f.r. ($d$-1)-point on $k$ followed by a substitution
\item the f.r. ($d$-1)-point on $k+1$ followed by a deletion
\end{itemize}
and then continuing as far as possible along the slide.
A point $(i,j)$ is furthest when its anti-diagonal $i+j$ is greatest.
The best alignment between reads A and B is the smallest $d$ such that $(m,n)\in W_{(0,0)}(d)$, where $m$ and $n$ are the length of reads A and B.
The O(ND) algorithm cimputes $d$-waves from starting point $(0,0)$ until the end point $(m,n)$ is reached.
The complexity of this algorithm is $O(n+d^2)$ when A and B are non-repetitive sequences \cite{Daligner}.
Because seeds are not always at the beginning, so waves are computed in both forward and reverse direction.
The latter is easily done by reversing the direction of edges in the edit graph.

\section{Seeding: concept}
To find suitable starting points for the edit graphs, seeding is done.
A seed is a section where $A[i,g]$ and $B[j,h]$ have a certain high similarity that indicates that these reads probably originate from the same part of the genome.
Finding a seed includes finding matching $k$-mers for every readpair $(a,b)$ with $a\in \mathcal{A}$ and $b\in \mathcal{B}$.
Previous methods to match $k$-mers include Suffix Arrays \cite{SA} and BWT indices \cite{BWT}.

Assuming that the $k$-mer matches are independent, the probablity that a $k$-mer is conserved while sequencing is $\pi = (1-2\epsilon)^k$.
The number of conserved $k$-mers in an alignment of $\tau$ basepairs is a Bernouilli distribution with rate $\pi$, so an average of $\tau\cdot\pi$ $k$-mers are expected in this alignment.
An example: $k=14$, $\epsilon=15\%$ and $\tau = 1500$, then $\pi = .7^{14} = 0.0067$ and the average number of conserved $k$-mers is 10.
Only $.046\%$ of the expected readpairs have 1 or fewer $k$-mers, and only $0.26\%$ have 2 of fewer.
To filter with $99.74\%$ sensitivity, only readpairs with 3 or more $k$-mer matches need to be examined.

The specificity of the filter is increased in two ways:
\begin{itemize}
\item computing the number of $k$-mer matches in diagonal bands of width $2^s$ instead of in the whole reads
\item thresholding on the number of bases in $k$-mer matches, instead of the number of $k$-mers themselves
\end{itemize}

The first way decreases the false positive rate because it only allows readpairs that have their $k$-mer matches relatively close, indicating a smaller region with higher similarity.
The second way relies on the fact that 3 overlapping $k$-mers have a higher probability ($\pi^{1+2/k}$) than 3 disjoint $k$-mers with $3k$ basepairs ($\pi^3$).


The actually find the $k$-mer matches, Daligner uses a sort-merge procedure:
\begin{itemize}
\item Build a list $List_X = \{(kmer(X_x,i),x,i)\}_{x,i}$ of all $k$-mers for database $X \in \{\mathcal{A},\mathcal{B}\}$, where $kmer(R,i)$ is the $k$-mer $R[i-k+1,i]$.
\item Sort both lists in order of their $k$-mers.
\item Merge the two lists and build $List_M=\{(a,b,i,j): kmer(A_a,i) = kmer(B_b,j)\}$ of read and position pairs that have the same $k$-mer.
\item Sort $List_M$ lexicographically on $a$, $b$ and $i$ where $a$ is most significant.
\end{itemize}

All entries for a certain read pair $(a,b)$ are in a continuous segment of the list.
This makes it easy to determine if that read pair has enough $k$-mers and in the right places to constitute a seed hit.
Given parameters $h$ and $s$, each entry $(a,b,i,j)$ for the current read pair is placed in diagonal bands $d = \lfloor(i-j)/2^s\rfloor$ and $d+1$.
Now determine the number of bases in the A-read covered by $k$-mers in each pair of neighbouring diagonal bands.
Note that only bases in matching $k$-mers are counted, not the number of $k$-mers.
When there are k+1 matching consecutive bases, two $k$-mers are generated.
These are less 'valuable' than two non-overlapping $k$-mers.
If $Count(d) \ge h$ for any diagonal band $d$, there is a seed hit for each position $(i,j$) in the band $d$ unless position $i$ was already in the range of a previously calculated local alignment.

%TODO insert image of diagonal bands

The best values for $h$ and $s$ depend on things like $\epsilon$ and the read lengths.

For Daligner, the default $k$ is 14, and assumed error rate is $0.85$.

%TODO include time analysis?


\section{Seeding: implementation}
Daligner is designed to use multiple threads and use the cache efficiently.
Building and merge the lists in steps 1 and 3 is easy, since only one pass is needed for both actions.
The elements of the lists are compressed into 64-bit integers.
Daligner uses a radix sort \cite{sorting}\cite{radix} to sort the lists in steps 2 and 4.
Each 64-bit integer is a vector of $P=\lceil hbits/B\rceil$, $B$-bit digits ($x_P,x_{P-1},x,...,x_1$) where $B$ is a parameter.
The sort needs $P$ passes, where each pass sorts the elements on a $B$-bit digit $x_i$.
Each pass is done with a bucket sort \cite{sorting} with $2^B$ buckets.
Instead of a linked list, the integers in the list $src$ are moved in precomputed segments $trg[bucket[b]...bucket[b+1]-1]$ of an array $trg[0...N-1]$ with the same size as $src$.
For the $p^{th}$ pass, $bucket[b] = \{i: src[i]_p < b\}$ for each $b \in [0,2^B-1]$.

%TODO include code segment?

\lstinputlisting{\code radix1.c}

The algorithm takes $O(P(N+2^B))$ time, but $B$ and $P$ are small fixed numbers so it is effectively $O(N)$.
There are a lot of parallel sorting algorithms \cite{parRadix1}\cite{parRadix2}, but Daligner uses a new method that needs half the number of passes that traditional methods use.
Each thread sorts a contiguous segment of size $part = \lceil N/T\rceil$ of $src$ into $trg$, where $T$ is the number of threads.
This means each thread $t \in [0,T-1]$ has a bucket array $bucket[t]$ where $bucket[t][b] = \{i: src[i] < b$ or $src[i] = b$ and $i/part < t\}$.
To reduce the number of passes, a bucket array for the next pass is filled during the current pass.
Each thread counts the number of $B$-bit digits that will be handled in the next pass by itself and every other thread seperately.
If the number at index $i$ will be at index $j$ and in bucket $b$ next pass, then the count in the current pass must not be recorded for the thread $i/part$ that currently sorts the number, but for thread $j/part$ that will sort it in the next pass.
To do this we need to count the number of these events in $next[j/part][i/part][b]$ where $next$ is a $T\times T\times 2^B$ matrix.
If $src[i]$ is about to be moved in the $p^{th}$ pass, then $j = bucket[src[i]_p]$ and $b = src[i]_{p+1}$.



\end{document}















