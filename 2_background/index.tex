\documentclass[../main/thesis.tex]{subfiles}

\begin{document}

\chapter{Background}
\ifdefined\main
\acresetall
MAIN IS TRUE
\newcommand{\codePath}{../2_background/code/}
\newcommand{\figPath}{../2_background/figures/}
\else
MAIN IS NOT TRUE
\input{../notmain.tex}
\fi


\section{Cell and Molecular biology}
The most basic unit for a living organism is a \textit{cell}, often called the 'building blocks of life'.
Each living thing consists of one or more cells.
Cells can have different shapes, sizes and functions, but they all have some things in common.
Each cells consists of cytoplasm surrounded by a membrane.
This membrane is the boundary between the exterior and the inside of the cell and acts as a filter to allow certain molecules to enter or exit the cell.
A cell can grow by taking nutrients from the environment, and using them to create other molecules, or letting them interact with existing molecules \cite{bioinformatics}.
Cells can also reproduce when there are enough components in the original call to produce a duplicate cell.
Many processes in the cell are driven by \textit{proteins}.
Proteins are long chains of \textit{amino acids}.
These amino acids are joined by peptide bonds to form polypeptides.
When these polypeptides are folded by the forces between the atoms, it is called a protein.
The exact form of the protein is crucial to its function \cite{protein_misfolding}.
Examples of protein functions are breaking down molecules like other proteins, fat or carbyhydrates, fighting off foreign particles like viruses or bacteria, and assisting in a chemical reaction, in which case the protein is called an \textit{enzyme} \cite{protein_function}.
Enzymes bind to the reagents of the reaction to lower the activation energy and increase the speed of the reaction, but they are not consumed during the reaction and can be reused.
Enzymes are usually highly specific, meaning that they will only catalyze certain reactions \cite{enzyme_specificity1}\cite{enzyme_specificity2}.

It is clear that proteins play a huge role in sustaining a cell.
The information needed to create proteins is stored in \textit{DNA} or deoxyribonucleic acid.
DNA can be \textit{translated} to create new proteins (this proces is called \textit{genetic expression}), or \textit{replicated} to allow for reproduction.
A section of DNA that codes a certain protein is called a \textit{gene}.
A DNA molecule consists of two long chains of nucleotides (also called strands), which are intertwined with eachother in a double helix.
Each nucleotide is composed of a nucleobase, a sugar called deoxyribose and a phosphate group \cite{dna_structure}.
The four different nucleobases are: adenine (A), thymine (T), cytosine (C) and guanine (G).
The bases of one strand bond with bases in the opposite strand, but adenine can only bond with thymine, and cytosine only with guanine.

\figC{width=\textwidth}{dna_structure.jpeg}{Structure of DNA \cite{dna_structure_fig}}{fig:dna_structure}

Each strand has two ends: the \textit{5'-end} (pronounced five-prime) and the \textit{3'-end}.
The 5'-positions can bind a phosphate group, the 3'-positions can bind a sugar.
This leads to a \textit{backbone} of alternating sugar and phosphate groups.
The two strands are \textit{antiparallel}, this means one strands 5'-end is matched to the others 3'-end.
The orientation of the strand is significant: replication and translation can only be done in 5'$\rightarrow$3' direction.

%TODO add DNA replication
% use picture from http://academic.pgcc.edu/~kroberts/Lecture/Chapter%207/replication.html
% as source

During DNA replication, DNA polymerase...

\figC{width=\textwidth}{dna_replication.jpg}{Molecules involved in DNA replication, source \cite{dna_replication_fig}}{fig:dna_replication_fig}

Creating new proteins from DNA is done via messenger RNA or \textit{mRNA}, which looks like DNA, but has only one strand.
It has the same structure as DNA, but thymine (T) is replaced by uracil (U), and the sugar is \textit{ribose} instead of deoxyribose.
When reading the DNA, three bases are considered together, and are called a \textit{codon}.
Each codon describes an amino acid, but since there are only 20 different amino acids, and $4^3=64$ different codons, multiple codons map to the same amino acid, and some codons have special functions, like start (ATG) and stop (TAA, TAG, TGA) \cite{codons}.

The process starts with the enzyme \textit{RNA polymerase} binding to the correct place on the DNA with the help of a \textit{promotor}, which indicates the start of a gene.
The mRNA strand will look like the \textit{coding (or sense) strand} of the DNA, the other DNA strand is called the \textit{template (or antisense) strand}.
The RNA polymerase create a so-called \textit{transcription bubble}, which is a short section of seperated DNA, where the RNA polymerase can access the bases of the coding strand.
The polymerase now adds RNA nucleotides to the template strand, creating an mRNA strand.
This strand is seperated from the DNA template strand, allowing the DNA strands to join back together.
The mRNA strand now looks like the DNA coding strand, with the exception that thymine is replaced by uracyl.

The mRNA strand is now ready to be translated into a protein, this is done by a \textit{ribosome}, a very complex molecule consisting of several ribosomal RNA molecules and dozens of proteins \cite{DNA_translation1}.
The ribosome binds to the start of the mRNA strand.
The codons of the mRNA strand are interpreted by \textit{transfer RNA} (tRNA).
The first tRNA molecule binds to the start codon (AUG), and always carries the amino acid methionine.
The ribosome then keeps finding tRNA molecules that fit the mRNA codons, and adds their amino acids to the growing chain, creating the protein.
The tRNA molecules are not consumed during the process and can, after picking up a new amino acid, be reused.
There are no tRNA molecules that can fit a stop codon (UAA, UAG or UGA).
So instead of a tRNA molecule, a protein from a group called 'release factors' binds to the mRNA, and the ribosome releases the protein \cite{DNA_translation2}.
The used mRNA molecules degrade after they are used \cite{mRNA_degradation}.

The protein is now a chain of amino acids, linked together by peptide bonds.
This is called its \textit{primary structure} \cite{protein_structures}.
Most amino acids are nonpolar, this means their electrical charge is zero and balanced.
Others have positive or negative charges, or have no charge, but do have a dipole, these are called polar.
Polar amino acids can form hydrogen bonds \cite{hydrogen_bond}, charged amino acids can form ionic bonds \cite{ionic_bond}.
Hydrophobic amino acids can form weaker van der Waals bonds.
Most of these bonds noncovalent, which means they do not share electrons \cite{ionic_bond}.
Cysteine is the only amino acid that can form covalent bonds \cite{protein_structures}.

Bonds between parts of the protein can cause folding patterns to appear.
The most occurring types are \textit{alpha helices} and \textit{beta sheets}, shown in Figure \ref{fig:alpha_helix_beta_sheet}.
These patterns form the \textit{secondary structure} of a protein.
When these patterns interact with eachother, for example due to van der Waals bonds, the \textit{tertiary structure} forms.
Finally, a protein consisting of multiple chains, or subunits, is called the \textit{quaternary structure} \cite{protein_structures}.

\figC{scale=.3}{alpha_helix_beta_sheet.jpg}{Alpha helix and beta sheet visualized, source: \cite{alpha_helix_beta_sheet}}{fig:alpha_helix_beta_sheet}

A partially folded protein can interact with different molecules in the cell, causing improper folding.
Misfolded proteins can also clot together with other molecules, causing large aggregates.
To prevent this, \textit{chaperone proteins} surround a protein during the folding process.
Many chaperone proteins are \textit{heat shock} proteins, because heat makes proteins less stable.
The cells produces more heat shock proteins when it is exposed to heat \cite{chaperone_protein}.


\section{DNA sequencing}
DNA sequencing is the process of finding out which nucleotides make up a DNA molecule, or all DNA molecules of an organism.
Seperate DNA molecules are called 'chromosomes'.
Humans have 46 chromosomes, containing about 3.5 billion basepairs \cite{DNA_human_stats} and about 20000 genes \cite{human_genes}.

Knowing the exact DNA sequence is useful for a number of applications: analyzing bacteria/virusses, analyzing genetic diseases, forensic analysis, ethnicity and ancestry analysis.

Another application is genetic modification of bacteria or plants.
If their DNA can be altered, they could produce useful substances at a very low marginal cost.

DNA sequencing has evolved over the years, becoming orders of magnitude cheaper and faster.

\subsection{Sanger sequencing}
Sanger sequencing, also called chain-termination sequencing, is the first major DNA sequencing technique.
It is published in 1977 \cite{Sanger}, and later improvements led to the development of commercial DNA sequencing machines in 1991 \cite{history_sequencing}.
It is also the technique used by the Human Genome Project \cite{sanger_sequencing2}, a project to sequence the whole genome of a human.
The project start around 1990, and finished in 2003 \cite{human_genome_project}.
Since Sanger sequencing has a maximum chain length of about 900 basepairs \cite{sanger_sequencing2}, the resulting pieces of DNA had to be assembled after sequencing.

To sequence a DNA sample, it is mixed in a tube with: a \textit{primer}, DNA polymerase, normal DNA nucleotides (dATP, dTTP, dGTP and dCTP), and dye-labeled, chain-terminating dideoxynucleotides.
The primer is a piece of DNA that can fit onto a specific spot of a DNA strand.
Primers usually contains 18 to 24 bases \cite{sanger_primer_size}.
The chain-terminating nucleotides are ddATP, ddTTP, ddGTP and ddCTP.
They consist of a normal nucleotide, but with an oxygen atom removed, as shown in Figure \ref{fig:ddNTP}.
This small difference means that no new nucleotide can be attached to it, thus ending the chain.
The mixture is heated to split the two DNA strands.
Once the primer is bound, the DNA polymerase can start adding nucleotides to form a chain.
At one point, a dideoxynucleotide is added, and the chain cannot grow anymore.
The distribution of chain lengths is determined by the ratio of normal and dideoxynucleotides \cite{sanger_ratio}.

After a certain period, most of the dideoxynucleotides have terminated a chain, and the next phase can begin.
The chains are sorted by length by means of \textit{cappilary electrophoresis} (CE).
During CE, the chains are run through a long glass capillary filled with a gel polymer.
An electrical field is applied and the DNA fragments move through the capillary.
The speed of the fragment is inversely proportional to its weight, so the shortest chains arrive earliest at the end.
The resolution is high enough to seperate chains that differ in length by one base.
A laser excites the dye-labeled dideoxynucleotides, which emits a light at a characteristic wavelength.
These lights are detected and interpreted to get the actual DNA sequence.

\figC{scale=.5}{ddNTP.png}{Normal nucleotides and dideoxynucleotides, source: \cite{sanger_sequencing2}}{fig:ddNTP}
\figC{scale=.5}{sanger_sequencing.png}{Workflow of Sanger sequencing, source: \cite{sanger_sequencing2}}{fig:sanger_sequencing}

\subsection{Next Generation Sequencing}
Next Generation Sequencing (NGS) involves a number of different techniques.
They are different from the previous Sanger sequencing in that they are massively parallel, have high throughput at a much lower cost \cite{ngs_history}.

% Pyro
% SOLiD
% Illumina, reversible dye terminators

The first NGS method is \textit{pyrosequencing}, developed in 2005 \cite{history_sequencing}.
Like Sanger sequencing, it is a \textit{sequence-by-synthesis} method, because it relies on DNA polymerase to recreate the DNA.
The DNA strand is split, and fragmented to pieces, which are attached to microscopic beads.
The strands are cloned using Polymerase Chain Reaction (PCR) \cite{dna_cloning}\cite{ngs_sequencing_atdbio}, such that each bead has about 10 million identical copies of its fragment \cite{pyro_sequencing2}.
Each bead is place into a separate well, and each well is given a mixture that contains DNA polymerase, adenosine phosphosulfate (APS), ATP sulfurylase, luciferin, and luciferase.
ATP sulfurylase is an enzyme that combines APS and pyrophosphate (PPi) into ATP, an energy carrier.
For one cycle, one type of nucleotide is added to each of the wells.
When a nucleotide is added to the chain by DNA polymerase, it releases PPi.
This is converted to ATP by ATP sulfurylase, this energy is used by luciferase to oxidize luciferin and create light.
The amount of light is proportional to the amount of nucleotides added, and since it is known which type of nucleotide is added, the bases can be read.
The wells are cleaned by the enzyme apyrase, which degrades ATP and the unused nucleotides.
Now, the next type of nucleotide can be added.
The whole sequencing process is shown in Figure \ref{fig:pyro_sequencing}.

The newest pyrosequencing machines can produce readlenghts up to 700 basepairs.

\figC{scale=.5}{pyro_sequencing.jpg}{Workflow of pyrosequencing, source: \cite{pyro_sequencing_fig}}{fig:pyro_sequencing}

%%%%%%%%

The most popular NGS method is created by Illumina \cite{most_popular_ngs}, released in 2007.
It is similar to Sanger sequencing, but uses \textit{reversible terminators}.
Another major difference is that instead of emulsion PCR, bridge PCR is used, which is more efficient \cite{ngs_sequencing_atdbio}.
Bridge PCR is further explained in Figures \ref{fig:bridge_pcr} and \ref{fig:bridge_pcr_comp}.
At the end of the PCR step, the reverse strands are washed away \cite{bridge_pcr_reverse}.
The reversible terminators are regular nucleotides, but fluorescent dye occupies the 3' end.
First, the reversible terminators are added, and bound by the DNA polymerase.
The unused nucleotides are washed away, and the dye of the bound nucleotides is released by an enzyme, allowing the bases to be read, and the chain to be extended during the next cycle.

Reads produced by this method are shorter (about 100 basepairs \cite{ngs_history}\cite{pyro_sequencing1}).

\figC{scale=.5}{bridge_pcr.png}{Process of bridge PCR, source: \cite{ngs_sequencing_atdbio}}{fig:bridge_pcr}
\figC{scale=.5}{bridge_pcr_comp.jpg}{(a) emulsion PCR, (b) bridge PCR, (c) emulsion PCR results in beads with cloned DNA strands, each well can fit one bead, (d) bridge PCR results in clusters of cloned DNA strands, source: \cite{history_sequencing}}{fig:bridge_pcr_comp}

Illumina also developed paired-end (PE) sequencing.
Both ends of a DNA strand are sequenced, with an unsequenced gap in the middle, this creates more data per DNA strand, but also valuable information, since the length of the strand is known.
These paired-end reads can be used during assembly, namely during the scaffolding phase.

\figC{scale=.5}{paired_end.jpg}{Source: \cite{paired_end_fig}}{fig:paired_end}

%%%%%%%%

The third major NGS method is Sequencing by Oligonucleotide Ligation and Detection (SOLiD), released by Applied Biosystems Instruments (ABI), which later became Life Technologies \cite{history_sequencing}.
SOLiD relies on ligation to chain nucleotides.
DNA ligase is able to ligate double-stranded DNA \cite{ngs_sequencing_atdbio}, whereas DNA polymerase only adds one base to a growing chain, complementary to a template strand \cite{dna_replication}.

A single strand DNA piece, known as an adapter, is merged with the template strand on one side, and attached to a bead on the other.
A primer of length N is connected to the adapter.
Now the DNA ligase can add oligonucleotides, these are strands of eight nucleotides, with fluorescent dye at the 5' end, shown in Figure \ref{fig:solid_color_coding}.
The first two bases have to be complementary to the bases in the template strand.
The degenerate and universal bases are not used.
Silver ions are used to cleave the link between bases five and six, allowing the dye to be observed.
The cleave leave a normal 5' end, which can be used to bind new oligonucleotides.
After the first round of sequencing, the new chain is removed, and a second round is started, but with a primer of length N-1.
Multiple rounds with primers with different lengths ensure that each bases is measured twice.
After the rounds, the colors can be decoded to get the actual bases, like in Figure \ref{solid_color_decoding}.
The total workflow in shown in Figure \ref{fig:solid_workflow}.

Because each base is measured twice, the accuracy can go up to 99.999\% with six primers, which is the highest of the NGS methods \cite{ngs_sequencing_atdbio}.
A downside is that the read lengths are usually short, 50 to 75 basepairs \cite{ngs_history}.

\figC{scale=.5}{solid_color_coding.jpg}{Color coding of SOLiD sequencing results, source: \cite{solid_color_coding}}{fig:solid_color_coding}
\figC{scale=.3}{solid_color_decoding.png}{Color decoding of SOLiD sequencing results, source: \cite{solid_color_decoding}}{fig:solid_color_decoding}
\figC{scale=.4}{solid_sequencing.png}{Workflow of SOLiD sequencing, source: \cite{ngs_sequencing_atdbio}}{fig:solid_workflow}

There are two other popular NGS techniques: DNA Nanoball Sequencing (DNBS) and Ion Torrent.
DNBS relies on Rolling Circle Amplification to clone the DNA strands that need to be sequenced.
The cloned strands are sequenced like in SOLiD sequencing \cite{ngs_history}.
Ion Torrent is very similar to pyrosequencing, but uses hydrogen ions instead of fluorescent dye to detect bases \cite{ngs_sequencing_atdbio}.
The number of ions is proportional to the number bases that was attached, however, at large repeating sections the accuracy decreases.
Ion Torrent produces reads of up to 400 basepaires, but the error rate is relatively high at 1.5\%.


\subsection{Third Generation Sequencing}
There is no clear division between Next Generation Sequencing and Third Generation Sequencing (TGS).
The technological improvements follow eachother quickly, and do not usually fit into welldefined timescales \cite{window_tgs}.
However, an often used definition is that TGS approaches are able to sequence a single DNA molecule, thus eliminating the need for amplification \cite{history_sequencing}\cite{ngs_sequencing_atdbio}.

The first TGS method is created by Helicos Biosciences, a company that went backrupt in 2012 \cite{history_sequencing}.
DNA template strings are attached to a surface.
Fluorescent nucleotides called Virtual Terminators are added, the dye is then cleaved off and detected.
The samples are washed, and a new type of nucleotide can be added.
The sequencing time for this method is relatively high, because only one type of nucleotide can be read at once, like with most NGS methods.
The read lengths are also quite short: about 32 nucleotides \cite{window_tgs}.

The other TGS are roughly placed into three categories: (a) sequencing by synthesis, (b) sequencing by nanopore, (c) direct imaging \cite{window_tgs}.

One of the most used TGS platforms is the Single Molecule RealTime (SMRT) sequencing platform from Pacific Biosciences.
It is based on sequencing by synthesis.
A very important part of SMRT sequencing is the Zero-Mode Waveguide (ZMW) technology.
A ZMW is a very tiny hole, with a diameter of 60-100 nm, and a height of 100 nm \cite{zmw}.
The metal that the holes are created in is placed on a glass substrate, giving the holes a glass bottom.
At the bottom of each well is a DNA polymerase molecule attached.
The wells are illuminated from beneath, by a laser with a wavelength of approximately 600 nm \cite{history_sequencing}.
The diameter of the well is important, because it is smaller than the wavelength of the used light, the light penetrating the bottom of the well decays exponentionally, such that only the bottom of the well is illuminated.
The well is filled with fluorescent nucleotides, and as one of these is held by the polymerase, a light pulse is produced and recorded.
There are other nucleotides floating in the well, but the nucleotides held by the polymerase is illuminated approximately three orders of magnitude longer, this creates a high signal-to-noise ratio \cite{window_tgs}.
As the polymerase does not have to wait for the nucleotides to be washed away, the process is realtime, which greatly increases the sequencing speed.
Another advantage is that it produces some of the longest read lengths in the industry, with an average of 10000 basepairs, and longest reads of 60000 basepairs \cite{pacbio_readlength}.
The fluorescent dyes are attached to the phosphate chain, which is cleaved off naturally when incorporated into the DNA strand, as shown in Figures \ref{fig:dna_replication_fig} \ref{fig:pacbio_dye}.

\figC{scale=.4}{pacbio_dye.jpeg}{(a) A zero-mode waveguide with a DNA polymerase molecule at the bottom (b) a dyed base is incorporated into the strand, and the phosphate groups with tye dye are cleaved off, source: \cite{pacbio_dye}}{fig:pacbio_dye}

\figC{scale=.8}{pacbio.jpg}{A: a ZMW with DNA polymerase and a DNA template strand, B: a C nucleotide is added to the chain, the next one is an A, source: \cite{pacbio}}{fig:pacbio}

\figC{width=.8\textwidth}{pacbio_readlength.jpeg}{A distribution of read lengths, from a human library, source: \cite{pacbio_readlength} Courtesy of Pacific Biosciences of California, Inc., Menlo Park, CA, USA}{fig:pacbio_readlength}

A new application of SMRT sequencing includes adding single-stranded loops to a double-stranded template, creating a circular template called a SMRTbell \cite{SMRTbell}.
The double-stranded DNA region and single-stranded loops are called insert and hairpins respectively.
The insert can be of any length, where lengths from 40 bp to 25000 bp have been tested \cite{SMRTbell}.
The hairpins contain a sequence to which a primer can bind to.
When the whole SMRTbell is sequenced, the DNA polymerase arrives at the 5' end of the primer.
The primer is seperated from the SMRTbell, and the sequencing can continue.
This means that length of the sequence can become much larger than the length of the insert, depending on the lifetime of the polymerase \cite{pacbio}.
After sequencing, the reads can be split up by removing the hairpin regions, to obtain subreads.
Since each base can be sequenced multiple times, a consensus sequence can be constructed from all subreads, with a quality score for each base.

\figC{width=.6\textwidth}{SMRTbell.jpeg}{(a) A SMRTbell template has a double-stranded region (insert) and two hairpin loops on the side. The orange part is a primer. (b) As the regions split, a circular template is formed, which is sequenced from both template and coding strand. The seperated part contains the orange primer, source: \cite{SMRTbell}}{fig:SMRTbell}

\figC{scale=.5}{SMRTbell2.jpg}{Since the SMRTbell is circular, the insert can be sequenced multiple times, the resulting read is split, and a consensus sequence is created, source: \cite{SMRTbell2} Courtesy of Pacific Biosciences of California, Inc., Menlo Park, CA, USA}{fig:SMRTbell2}

PacBio's SMRT sequencing also has some disadvantages: throughput and error rate.
Only 23-46\% of the ZMWs produce succesful reads \cite{history_sequencing}.
This can be caused by failing to attach a polymerase molecule to the bottom of a ZMW, or by loading more than one DNA strand in a ZMW.
The throughput of the older RS II system is about 2 billion bases per day, but the newer Sequel System can produce 20 billion bases per day \cite{pacbio_throughput}.
Still, this is much lower than the high throughput offered by Illumina HiSeq 2500, with HiSeq SBS v4 reagent kits, it can produce about 167 billion bases per day in High Output Run Mode \cite{pacbio}.

%%%%%%%%

A nanopore is a small opening through which a DNA molecule can move, one base at a time.
While doing this, these bases can be detected by an electrical or optical signal.
The nanopore are usually made of biological proteins, or synthetic structures like carbon nanotubes \cite{nanotubes}.
Oxford Nanopore Technologies (ONT) has build a system for DNA sequencing where three natural biological molecules form a nanopore.
This system is called MinION and is a tiny portable DNA sequencer, shown in Figure \ref{fig:minION}.
The nanopore is put in a synthetic lipid bilayer, which consists of two sheets of lipid molecules forming a thin polar membrane.
A voltage is applied accross the bilayer, causing an ionic current through the nanopore.
The double-stranded DNA is extended with a lead adaptor with a molecular motor, a hairpin adaptor, and a trailing adaptor.
These adaptors enable the nanopore and DNA molecule to bond.
The motor includes a processive enzyme, which denatures the DNA strands, and moves one strand through the nanopore at sufficient speed.
The adaptors also concentrate the DNA around the nanopore, increasing the DNA capture rate by several thousand-fold \cite{minION}.
As the bases move through the nanopore, they disrupt the ionic current flowing through the pore.
Since the nucleotides have different shapes, the disruption they cause is also different.
The exact change on the ionic current must be measured to determine the nucleotide.

Figures \ref{fig:nanopore} and \ref{fig:nanopore2} show the working of the nanopore.

\figC{width=.3\textwidth}{minION.jpg}{A MinION device connected to a USB 3.0 cable, source: \cite{minION_fig}}{fig:minION}

\figC{scale=.8}{nanopore.jpg}{Double-stranded DNA gets denatured by an enzyme (1), one of the strands moves through the nanopore (2), adapted from: \cite{history_sequencing}}{fig:nanopore}
\figC{width=\textwidth}{nanopore2.png}{(i) nanopore is empty, (ii) dsDNA with lead adaptor (blue), molecular motor (orange) and hairpin adaptor (red), (iii) lead adaptor, (iv) template strand (gold), (v) hairpin adaptor, (vi) complement strand (dark blue), (vii) trailing adaptor (brown), (viii) nanopore is empty again, adapted from: \cite{minION}}{fig:nanopore2}

Oxford Nanopore boasts very long reads, over 200 kilobases, but a disadvantage of using this system is the error rate is very high: 12-38\% \cite{minION_error1}\cite{minION_error2}.

%%%%%%%%

The third category is direct imaging, usually with some sort of microscope.

A Transmission Electron Microscope (TEM) can be used to detect atoms attached to nucleotides.
The atoms that normally make up nucleotides are too small and light to be detected, so heavy elements elements are added, like Mercury \cite{tem}.
To be able to read the bases, the DNA's natural state, a double helix, must be flattened and placed on a substrate.
Some ways to prepare the DNA molecules include combing \cite{combing1}\cite{combing2}, molecular threading \cite{molecular_threading} and transfer printing \cite{transfer_printing}.

\figC{width=.6\textwidth}{flatDNA1.png}{Different forms of double-stranded DNA, source: \cite{tem2}}{fig:flatDNA1}

ZS Genetics uses annular dark-field (ADF) imaging \cite{ADF}.
Dark-field imaging measures the photons/electrons that have come into contact with the object, leaving out the uninterrupted beam.
Light-field imaging is the opposite: it measures the amount that did not get interrupted.
Annular dark-field imaging uses an annular (ring) to capture the photons/electrons, as shown in Figure \ref{fig:ADF}.


\figC{width=.6\textwidth}{ADF.png}{Top: electrons are scattered by heavy atoms and detected. Bottom: unlabeled DNA bases scatter fewer electrons and are harder to detect, source: \cite{tem}}{fig:ADF}

\figC{width=.6\textwidth}{tem_label.png}{Single-strand DNA is primed and a complementary strand is synthesized. Thymine nucleotides have a heavy atom attached, source: \cite{tem}}{fig:tem_label}

\figC{width=.6\textwidth}{flatDNA2.png}{A labeled DNA molecule, ready to be read. Image on the right shows an image from an ADF STEM, source: \cite{tem2}}{fig:flatDNA2}

Another microscope capable of sequencing DNA is the Scanning Tunneling Microscope (STM) \cite{STM}.
The machine is invented in 1982 by Binnig and Rohrer, for which they won the 1986 Nobel Prize in Physics \cite{STM_nobel}.
The conductive tip of the machine is located very close to the sample, which is deposited on a conductive surface.
The tip is extremely thin, to allow for very precise spatial measurements.
Electrons can move from the sample to the tip, by tunneling \cite{STM_harvard}, a voltage difference between the sample and the tip is applied to allow for this phenomenon.
The tunneled electrons form a current, which can be measured.
This current is very sensitive to the distance between the tip and the sample, a change of $10^{-10}$ m can cause the current to change an order of magnitude \cite{STM_DNA}.
The width of a DNA molecule is about $2\cdot10^{-9}$.
The current can also depends on the applied voltage.
This means the current can be used to measure the exact distance between the tip and the sample.
At least, that is the theory.
The reality is that DNA has a low conductivity when attached to a hard surface \cite{STM_DNA2}.
As the tip moves closer to the sample to try and get a current, it touches the DNA, deforming it \cite{STM_DNA}.
Other challenges include difficulties in preparing clean samples and the fact that measurements can only be done at cryogenic temperatures \cite{STM_DNA2}.
These, and the relatively high costs of an STM, are probably the reasons why there is currently no practical case for STMs in DNA sequencing.

%%%%%%%%

A different approach combines nanopores and tunnel current.
Traditional nanopores, like from Oxford Nanopore Technologies, measure ionic current to determine the base that occupies the nanopore.
A drawback of this method is throughput: a base has to block the pore long enough for the current to change and be measured.
This is done by stopping, slowing down, or cleaving bases off.
In either case, the read out of the current is in the order of tens or hundres of ms \cite{nanopore_tunnel2}.
The new approach measures the tunneling current between two electrodes that make up a nanopore.
Using tunneling currents can potentially be orders of magnitude faster than using ionic currents, because electrical currents can easily be detected in ranges of over MHz and possibly tens of MHz for the current amplitudes (tens of pA to nA) \cite{nanopore_tunnel2}.
By applying a trans-membrane voltage, the movement of the DNA strands can be controlled, and using tunneling current gives a fast, accurate readout.
In 2005, it was shown that each nucleotide has a unique electrical signature, which is independent of its nearest-neighbours \cite{nanopore_tunnel}.
In 2013, Quantum Biosystems was founded \cite{quantum_biosystems}.
They have two generations of devices, and use nanopores with a diameter of 0.8 nm \cite{quantum_biosystems2}.

\figC{width=.6\textwidth}{nanopore_tunnel.jpg}{(a) a traditional nanopore measuring the ionic current in the direction of the ssDNA strand, (b) a tunneling nanopore measuring the tunneling current perpendicular to the ssDNA strand, source: \cite{nanopore_tunnel1}}{fig:nanopore_tunnel}

\section{DNA Alignment}
DNA alignment involves determining the similarity between two DNA reads, a high similarity indicates the two reads originated from the same part of the genome.
This information can be used to reconstruct the whole genome, during the assembly phase.
%TODO: possibly refer to the next section 'DNA Assembly'?
An example of an alignment is shown in Figure \ref{fig:alignment}.

\figC{width=.6\textwidth}{alignment.png}{An example alignment, vertical stripes indicate matching nucleotides, horizontal stripes indicate gaps in one of the reads, source: \cite{alignment_fig}}{fig:alignment}

If the two reads originate from the same part of the genome, the mismatches can be explained by sequencing errors.
But copying the genome during cell division can also cause errors \cite{dna_replication_errors}.
Since DNA sequencing is usually performed on more than one cell, the variations in these cells are all sequenced.
%TODO: citation needed

The mismatches between reads can be distinguished between substitutions, insertions and deletions.
A substitution is shown between the fifth bases in the figure.
An insertion is where a read has a base that does not occur in the other read, a deletion means the opposite.
Note that usually, it cannot be determined if read A has an insertion, or that read B has a deletion, unless they can be compared to other reads.
Due to the similarity between insertions and deletions, they are often referred to as 'indels'.

\textit{Dynamic} algorithms can be used to determine the best alignment between two reads.
A match increases the score, a mismatch (substitution) or indel decreases the score.
The alignment with the highest score is the most likely alignment.

A simple scoring scheme has a static score/penalty for an indel or mismatch, but biologically speaking, one larger gap is more likely to happen than two smaller gaps, since it is more likely to add arbitrary bases to an existing gap than to create such a gap.
%TODO: citation needed
This is why an affine gap penalty in the form of $y = a*N+b$ is often used, where $b$ is the gap open penalty, $a$ the gap extend penalty, and $N$ the number of bases in the gap - 1.
Other variations in gap penalty include constant ($y = a$), double affine (), convex ($y = a+b\cdot ln(N)$).
%TODO: add double affine description

%TODO: SW and NW, global vs local
Global alignment aligns the full length of both sequences.
Every base will either have a match/mismatch with a base from the other read, or a gap.
Local alignment will look for the two subsequences from the reads that have the highest score.
This means that low scoring regions could be ignored.
Local alignment is especially useful when the reads are very different in length.
If one read represents a whole genome of 10000 bases, and the other represents a small sequenced part of 100 bases, global alignment will contain at least 9900 gaps, and at most 100 matches.
Local alignment will ignore most of those gaps, and only match the small read to a small part of the larger read.
Figure \ref{fig:global_vs_local_alignment_fig} shows another example of a case where local alignment is better.

\figC{width=.6\textwidth}{global_vs_local.png}{Local alignment can find small, overlapping regions very well, source: \cite{global_vs_local_alignment_fig}}{fig:global_vs_local_alignment_fig}

%TODO: should this be a seperate subsection? Could be an appendix as well
\subsection{Dynamic programming}
Dynamic programming is a programming technique that solves problems by dividing them recursively into smaller, simpler problems \cite{Dynamic_programming1}.
An important aspect is that the subproblems overlap, saving the results of one subproblem to use in another subproblem.
This makes it different than a divide-and-conquer approach, where the problem is divided into non-overlapping subproblems \cite{Dynamic_programming2}.
Ther are two ways to solve these problems: top-down, and bottom-up.
Top-down is a direct result of the recursive formulation.
It starts by asking the end result, if this is not available, follow the recursion, and check for the answer(s) of the subproblem(s).
If these are available, use them, if not, calculate them and store them.
This technique is called memoization.
Bottom-up firsts solves the subproblems, and uses these results to build the solution for the original problem.


\subsection{Global alignment}
For global alignment, the Needleman-Wunsch algorithm \cite{NeedlemanWunsch} is widely used.
It was published in 1970, and designed to compare sequences of amino acids, but as both are represented by letters, comparing nucleotides works in the same way.
%TODO: mention and cite that NW is proven optimal

In Needleman-Wunsch, the smallest subproblems are trivial alignments, such as aligning two bases, or aligning zero bases in one read with N bases in the other.
The first can result in two cases: a match or a mismatch, the latter results in N gaps.
The alignments are built incrementally, a non-trivial alignment is always a combination of a smaller (known) alignment, plus a match, mismatch or indel.
The scores in this thesis used are $match = 1$, $mismatch = gap = -1$ unless stated otherwise.
Of these cases, the maximum resulting score is considered as the score for that alignment.
This recursion is shown in Equation \ref{eq:NW_recursion}, where $S(i,j)$ is the maximum score when aligning subreads $a[0:i]$ and $b[0:j]$, $s(a_i,b_j)$ is the (mis)match score of those two bases, and $gap$ is the gap penalty.

\begin{equation}
S(i,j) = max
\begin{cases}
S(i-1,j) - gap \\
S(i,j-1) - gap \\
S(i-1,j-1) + s(a_i,b_j) \\
\end{cases}
\label{eq:NW_recursion}
\end{equation}

The score of every calculated alignment is stored in a matrix, where the score in the bottom-right corner indicates the score of the total alignment.
To find out the actual alignment, like in Figure \ref{fig:alignment}, traceback must be performed.
Traceback starts at the bottom-right corner, and for each matrix element, the source of the maximum score is found, either because it was stored in a different matrix, or because it is recalculated.
The traceback of one element is shown in Figure \ref{fig:NW_traceback}.

\figC{width=.4\textwidth}{NW_traceback.png}{Calculating a single element, the source of its score is either element on the left, top, or top-left, this determines the direction of the traceback pointer.}{fig:NW_traceback}

The algorithm consists of three steps: initialization, filling the matrix, and performing traceback.
The initialization writes scores to the first row and column, as these alignments are trivial.
Figure \ref{fig:NW1} shows an initialized matrix.

\figC{width=.6\textwidth}{NW1.png}{The DP matrix, initialised, source: \cite{NW_online}}{fig:NW1}

The matrix is filled according to the recurrence relation, where the elements have to be calculating in a particular order, because certain previous values need to be known.
A filled matrix is shown in Figure \ref{fig:NW2}.

\figC{width=.6\textwidth}{NW2.png}{The DP matrix, filled, source: \cite{NW_online}}{fig:NW2}

The traceback starts at the bottom-right element.
This $S(N,M)$ element indicates the score of aligning the total reads in an optimal way.


\figC{width=.6\textwidth}{NW3.png}{The DP matrix, with the traceback path highlighted, source: \cite{NW_online}}{fig:NW3}



The affine gap penalty is implemented via 3 matrices, one for a match/mismatch, one for a gap in read A, one for a read in B.
%X[] = max(gap_open + M[], gap_extend + X[])


\subsection{Local alignment}

%TODO: mention multiple sequence alignment

Alignment algorithms are also useful in applications like textcomparison.


















\section{DNA Assembly}
Every DNA sequencing technique produces reads, which are pieces of data that represent a part of the sampled DNA, possibly containing some errors.
These length and error rate of these reads depend of the sequencing technique used, but they all have one thing in common: they have to be assembled to be useful.
DNA assembly tries to combine the reads into large, high quality parts.

The process of DNA assembly is often compared to taking a copy of a book, shredding it, and trying to piece is back together.
However, when taking a read and splitting it into two parts, there is no information indicating that the two parts were originally together, as it would with shredded paper.
This is why DNA is always oversampled, this means that each base is sequenced multiple times.
%If a short sequence of bases is found in multiple reads, overlaps can be found, and the reads are combined into a bigger read.
Figure \ref{fig:dna_assembly} shows a simplified assembly process.
%This process continues until there are no more reads to merge.
%What is left are large pieces of DNA called 'contigs'.

\figC{width=.6\textwidth}{DNA_assembly.png}{A DNA strand is cloned and sequenced, the reads are assembled and the original DNA strand is recovered, source: \cite{dna_assembly_fig}}{fig:dna_assembly}

There are two types of assembly: de-novo and reference based.
De-novo assembly works as described above, but reference based assembly first maps the reads to a reference.
If multiple reads map to the same place in the reference, they are likely to be overlapping.
De-novo assembly compares each read with every other read, resulting in a naive time complexity of $O(N^2)$, where N is the number of reads.
De-novo assembly is an NP-hard problem \cite{https://www.ncbi.nlm.nih.gov/pubmed/19580519}.
Mapping each read to a reference takes $O(N)$, and then a much smaller number of reads has to be compared with each other.

The drawback of reference based assembly is that a read must first be mapped to a reference, this means that reads that contain new or very different streches of DNA are filtered away, this results in a biased assembly.
Reference based assembly is good at finding small variations between the sampled DNA and the reference \cite{denovo_vs_reference}.

\subsection{Denovo assembly}
% denovo:
% velvet (ngs, dBG)
% abyss (ngs, k:27-36, dBG)
% daligner (tgs)
% allpaths
% euler-sr (dBG)
% vcake
% sharcgs (ngs, prefix, greedy)
% edena (ngs, olc)
% ssake (ngs, hash, prefix, greedy)
% spades (dbg)
% qsra (ngs, hash, prefix, greedy)
% Newbler (ngs, olc, seed: k:16)
% sga (ngs, olc, fm, BWT)
% SOAPdenovo2 (dBG)

% HGAP (tgs)
% Falcon (tgs)
% Canu (tgs)
% Hinge (tgs)

There are two types of denovo assemblers: string-based and graph-based.
String-based assemblers are greedy \cite{denovo1}.
Examples of string-based assemblers are SSAKE \cite{ssake}, SHARCGS \cite{sharcgs} and QSRA \cite{qsra}.
The greedy approach works like this: from the set of reads, pick the two strings that have the 'best' overlap and merge them, repeat until there is one string left or there are no suitable overlaps anymore.
The 'best' overlap can differ: a perfect overlap between two strings s and t is a string y, such that s = xy and t = yz for some non-empty strings x and z \cite{denovo2}, but different scoring schemes allowing a few mismatches here and there are possible.
A suitable overlap will have a minimum length: since there are only four different bases, a set will likely have two reads with an overlap of one base, one can imagine merging these is not likely to be correct.
The greedy approach requires all reads to be compared with all reads, which is not suited for the high througput of ngs systems.
Another problem are repeat regions, which are very common in eukaryotic genomes, the human genome can contain more than 50\% repeats or repetitive areas \cite{repeats1}\cite{repeats2}.

Figure \ref{fig:repeat_greedy} shows how a greedy algorithm can misassemble reads containing a repeat region.

\figC{width=.6\textwidth}{repeat_greedy.jpg}{Pieces of a repeat region (green) occur in multiple reads, fragments 2 and 6 have a bigger overlap than 2 and 3 or 5 and 6, causing a misassembly, adapted from: \cite{repeat_greedy_fig}}{fig:repeat_greedy}

For ngs reads, graph-based assemblers are used, which come in two flavors: overlap-layout-consensus (OLC) and de Bruijn Graph (dBG).
%TODO: give examples of OLC and dBG assemblers
The OLC assemblers first find overlaps and build an overlap graph.
Each node represents a read, and each edge represents an overlap between two reads.
During the layout phase, the graph is analyzed to find paths, corresponding to segments of the original genome.
The perfect graph contains one path that visists each node exactly once.
This problem can be described as finding a Hamiltonian Path \cite{Euler_Hamil_paths}, which is also an NP-hard problem \cite{ngs_difficulties}.
A Hamiltonian Path includes all vertices of a graph exactly once.
Assemblers that use the OLC approach are Newbler \cite{newbler}, SGA \cite{sga} and Edena \cite{edena}.

\figC{width=.6\textwidth}{olc.jpeg}{Overlaps are found and put in a graph, each arrow represents an overlap, a Hamiltonian path is found to create the contig, source: \cite{old_fig}}{fig:olc}

To build a de Bruijn Graph, each read is divided into kmers.
Each kmer represents a directed edge between two vertices, where the source vertex represents the first k-1 bases of the kmer, and the destination vertex the last k-1 bases of the kmer.
When a particular k-1 vectex does not exist, it is created, otherwise the existing one is reused.
This means there are at most $4^{k-1}$ vertices in the graph.
The weights of the edges indicate how many times a particular kmer is encountered.
The next step is to find an Eulerian Path \cite{Euler_Hamil_paths}, which is a path that includes all edges of a graph exactly once.
A small value of k means the number of vertices is limited, but it also creates more edges, and loses more information.
Examples of dBG assemblers are Velvet \cite{velvet}, ABySS \cite{abyss} and SOAPdenovo2 \cite{soapdenovo2}.

Constructing a dBG is easier than constructing an OLC graph, since no overlaps are computed.
It is also easier to find an Eulerian Path than to find a Hamiltonian Path.
However, there can be an exponential number of Eulerian Paths in a graph, where only one is needed.
De Bruijn Graphs are quite susceptible to sequencing errors, one substituted base causes k incorrect kmers.
Pair this with a often-used value of k between 19 and 27 and a PacBio error rate of about 15\%, and it is clear that the graph will contain a lot of incorrect edges.
Another drawback of using this strategy is that information is lost when dividing the reads into kmers.
This information could overcome short repeats in the genome.
That is the reason why a variant of the Eulerian Path problem was formulated: the Eulerian Superpath problem \cite{Eulerian_Superpath}.
It tries to find an Eulerian path, that contains a set of subpaths, given a graph and the set of subpaths.

The previously described methods cannot reconstruct the whole genome on their own, their output consists of contigs: sequences of bases which are known.
The next step is building scaffolds \cite{scaffold1}\cite{scaffold2}.
A scaffold consists of contigs and gaps.
The gaps contain unknown bases, denoted by 'N', but their lengths is roughly known.
To create scaffolds, paired-end reads can be used.
When two ends of the paired-end read are found in different contigs, these contigs are likely to belong next to eachother, with a gap between them.

%TODO consider talking about Optical Mapping to aid scaffolding
%TODO talk about error correction before/after assembly?

\subsection{Reference based assembly}
The biggest part in reference based assembly is finding the location in the reference that the read came from, this process is called 'mapping'.
Mapping is usually done by a 'seed-and-extend' method.
This means that first a position is found that is promising (seed), and then the algorithm looks at both ends of the seed to see if those parts also match with the reference.

The most used method of finding seeds is to divide the reads into k-mers.
A k-mer is a piece of DNA with exactly k bases \cite{Kmer}.
The reference is also divided into k-mers, and exact k-mer matches are found using various methods.
A popular and basic method is hashing, used by MAQ \cite{maq}, Seqmap \cite{seqmap}, Mosaik \cite{mosaik}, Snap \cite{snap}, Shrimp2 \cite{shrimp2}, Stampy \cite{stampy} and SeqAlto \cite{seqalto}.
A different approach uses BWT \cite{BWT} or suffix arrays \cite{SA} to find matches, used by BWA \cite{bwa}, Soap2 \cite{soap2}, Bowtie2 \cite{bowtie2}, BWA-SW \cite{bwa-sw}, Aryana \cite{aryana} and BFAST \cite{bfast}.
An uncommon approach is to use sorting to find matching k-mers, like in merge-sort \cite{mergesort}\cite{sorting}.
This technique is used by Slider \cite{slider} and Syzygy \cite{syzygy}.

The value of k is very important: too low and there will be too many hits, too high and there will not be enough hits.
The value is also dependent on the length of the reads, and the type of reference (a different k might be used for humans or bacteria).
Values between 12 and 32 are common.

When a seed is found, the rest of the read must also be checked against the reference.
This is the 'extend' part.
Not all mappers have an extend part, like SeqMap.
Most use Smith-Waterman for this stage.
Snap uses an $O(ND)$ algorithm from Ukkonen \cite{O_ND2}.
Stampy uses a probabilistic aligner to extend their seeds.
SeqAlto and Aryana use a banded Needleman-Wunsch.

When all the reads are mapped to the reference, they have to be combined.
This can be done by local denovo assembly, or a consensus algorithm \cite{consensus}.


% mappers:
% maq (hash)
% seqmap (hash)
% mosaik (hash, k:15, SW)
% snap (hash, O(ND))
% shrimp2 (hash, k:12, SW)
% stampy (hash, k:15, probabilistic aligner)
% seqalto (hash, k:17-32, banded affine-gap penalty NW)
% bwa (bwt)
% soap2 (bwt)
% bowtie2 (bwt, k:16)
% bwa-sw (bwt, SW)
% aryana (bwt, k:>16, banded NW)
% bfast (suffix, k:18-22)
% slider (sorting)
% syzygy (sorting)


\section{GPU processing}

%TODO also talk about OpenCL?
%TODO why GPU in the first place? What do they look like, what are they good at?
%TODO CUDA was released in 2006, source: programming guide

A GPU is a Graphics Processing Unit, it is a processor that is mainly used to perform video processing.
This type of processing often includes rotation and translation of objects in a space, calculating shadows and rendering images to display on a monitor.
They contain many cores that allow it to perform parallelizable tasks very quickly.
A GPGPU, or General Purpose GPU can be programmed to perform tasks that are different from video processing.
An algorithm like matrix addition is easily parallelized by assigning a matrix cell to each thread.
Each thread can perform the addition in parallel, let this take one cycle.
A sequential implementation would have taken $N\times M$ cycles, where $N$ and $M$ are the dimensions of the matrices.

CPUs usually have large caches and a complex instruction set and execution that includes out-of-order execution and branch prediction \cite{CPUvsGPU1}\cite{CPUvsGPU2}.

GPUs cannot operate on their own, they must be guided by a CPU.
A general workflow using a GPU is shown in Figure \ref{gpu:workflow}.

%TODO include gpu:workflow

\begin{itemize}
\item Copy data from CPU to GPU
\item Let GPU process the data
\item Copy results from GPU to CPU
\end{itemize}

The functions that run on a GPU are called \textit{kernels}, and are usually launched by a CPU.
Kernels can also be called from other kernels.


%TODO maybe divide into subsections
\section{CUDA}
CUDA is a parallel computing platform that allows people to use Nvidia GPUs for their own applications.
Developers can write functions that will execute on the GPU called \textit{kernels}, these are launched from a CPU function.
The GPU is referred to as \textit{device} and the CPU as \textit{host}.
Kernels for CUDA are written in C++.

Kernels can be launched from the CPU in a \textit{grid} with a certain number of thread blocks or \textit{blocks} and \textit{threads}.
A grid is one-/two- or three-dimensional, and has an array of blocks in each direction.
Each block itself is also one-/two- or three-dimensional, and has an array of threads in each direction.
Figure \ref{cuda:hierarchy} shows a full grid.

%TODO picture of hierarchy \label{cuda:hierarchy}
% possible source: http://international.download.nvidia.com/pdf/kepler/NVIDIA-Kepler-GK110-GK210-Architecture-Whitepaper.pdf

Each thread executes the kernel code, although they usually operate on different data.
Threads in a block can communicate via shared memory.

On a hardware level, an NVIDIA GPU is divided into Streaming Multiprocessors (SMX).
Each SMX contains a number of cores, or Streaming Processors (SP), these are the basic building blocks and perform the actual calculations.
Each block is assigned to at most one SMX.
This block's threads are then executed as warps, with 32 threads per warp.
Each SMX has multiple warp schedulers, so multiple warps can run in parallel on an SMX.
All threads in a warp must execute the same instruction, if a thread is the only to take a branch, the other threads must wait until the branch is completed, this is called divergence.

Memory operations are also executed in parallel, this means that all threads try to read/write to the memory in parallel.
If the addresses are next to eachother, only one memory transaction is needed, since a transaction processes a whole memory line.
This is known as coalescing.
Uncoalesced memory accesses cause multiple memory transactions.

\figC{scale=.5}{gpu_coalesced.png}{Uncoalesced accesses are inefficient, source: \cite{gpu_coalesced_fig}}{fig:gpu_coalesced}

%TODO include figure of hardware
%https://www.techpowerup.com/img/12-05-17/155a.jpg

%Tesla-Fermi-Kepler-Maxwell-Pascal-Volta


\subsection{Memory hierarchy}
GPUs have several different memory types and levels.
Not all of these are accessible from the host or from other components of the memory hierarchy \cite{cuda}. Figure \ref{fig:memory_hierarchy} shows three types of memory.
\begin{itemize}
\item Global memory: The largest and slowest memory, located outside the chip. Can be read and written from the host. Best used for coalesced operations.
\item Local memory: Each thread has private memory for when registers are not enough. It is cached in L1 cache, or stored in global memory when too large.
\item Registers: The fastest memory available, located on-chip. A thread has a maximum number of registers available depending on Compute Capability.
\item Shared memory: Each SMX has shared memory, it can be accesses by every thread in every block on the SMX. This can be used by threads in a block to communicate. It is located on-chip, so very fast.
\item Constant memory: The host can initialize this memory, the kernel can only read it. Reading is as fast as reading a register, but only when all addresses of a half-warp are the same, otherwise reading is serialized. It resides off-chip, but is cached on-chip.
\item Texture memory: Can only be written from the host. Resides off-chip, but is cached on-chip, like constant memory. The main feature about the texture memory is that it is cached for 2D spatial locality. Figure \ref{fig:texture_cache} shows an access pattern that would not be cached with a typical scheme.
\item L2 cache: Behaves as cache for device memory and is shared among all SMXs. The cache line size is 32B.
\item L1 cache: Cache line size is 128B. Its default behaviour is to only cache local memory, not global memory. However, for certain architectures applications can opt-in to cache both global and local loads in L1 \cite{L1cache}.
\end{itemize}

\figC{scale=.5}{memory_hierarchy.png}{Memory hierarchy \cite{cuda}}{fig:memory_hierarchy}

%\includegraphics[scale=.2]{\fig texture_cache.png}
\figC{scale=.2}{texture_cache.png}{This access pattern has spatial locality, and could be cached in the texture cache \cite{texture_cache}}{fig:memory_hierarchy}

\subsection{Streams}
When copying data to or from the GPU, there are usually no kernels running in a naive implementation.
This means that if the copy time is large, the overall efficiency is quite low.
These operations can be overlapped or pipelined by using streams. Figure \ref{fig:streams} shows how the execution time can decrease by overlapping copying and computing.

\figC{scale=.2}{streams.png}{Different versions of the same computation \cite{streams}}{fig:streams}





%TODO include this section? this work mainly focuses on GPU computation, instead of heterogeneous computation
\section{Heterogeneous computing}
%\cite{hetero_survey}


\subsection{Bioinformatics on GPU}

% BarraCUDA (align/mapping, ngs)
% CUDASW++ (mapping)
% CUSHAW (long read, align)
% GPU-BLAST (local alignment)
% GPU-HMMER (hidden Markov models, local alignment)
% mCUDA-MEME
% SeqNFind
% UGENE (SW, SA)



\end{document}










